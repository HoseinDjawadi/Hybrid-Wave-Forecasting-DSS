{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lJ9NOUmQZOxS","outputId":"c0c8dfff-fbc0-4ea2-a9e0-56c97464d7f7","executionInfo":{"status":"error","timestamp":1753719462450,"user_tz":-210,"elapsed":9309861,"user":{"displayName":"Mo Ho Seyed Djawadi","userId":"09814257735504616511"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["--- Step 1: Setup and Data Preparation ---\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n","Requirement already satisfied: interpret in /usr/local/lib/python3.11/dist-packages (0.7.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: interpret-core==0.7.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.7.1)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.6.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.5.1)\n","Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.9.5)\n","Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (6.17.1)\n","Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (7.34.0)\n","Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.24.1)\n","Requirement already satisfied: SALib>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.5.1)\n","Requirement already satisfied: shap>=0.28.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.48.0)\n","Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.3.8)\n","Requirement already satisfied: aplr>=10.6.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (10.9.0)\n","Requirement already satisfied: dash<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.18.2)\n","Requirement already satisfied: dash-cytoscape>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.0.2)\n","Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (25.5.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.32.3)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.0.3)\n","Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.0.6)\n","Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.0.0)\n","Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.0.0)\n","Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.0.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (8.7.0)\n","Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.4.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (80.9.0)\n","Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.1.1)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (7.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.8.15)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.1.7)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (6.4.2)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.7.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (4.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (8.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2025.7.14)\n","Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.10.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.70.16)\n","Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18.1->interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.6.0)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.1.1)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (8.2.1)\n","Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (5.8.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.2.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.43.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core==0.7.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (3.23.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.1->interpret) (4.3.8)\n","Mounting Google Drive...\n","Mounted at /content/drive\n","Google Drive mounted successfully.\n","Output directory will be: /content/drive/My Drive/Paper_3_New/Outputs/Modeling_v1/EBM\n","Attempting to load data from: /content/drive/My Drive/Paper_3_New/Outputs/Feature_Engineering_v1/final_engineered_features_v3.csv\n","Data loaded successfully.\n","Training/Validation set shape: (10538, 239)\n","Out-of-Sample (OOS) set shape: (7932, 239)\n","Target variable: buoy_main_hs\n","Number of features: 202\n","\n","--- Step 2: Implementing Blocked Time Series CV ---\n","BlockedTimeSeriesSplit class defined and CV splitters instantiated.\n","\n","--- Step 3: Hyperparameter Optimization with Nested CV ---\n","This step will take a significant amount of time.\n","\n","--- Starting Outer Fold 1/5 ---\n"]},{"output_type":"stream","name":"stderr","text":["[W 2025-07-28 16:17:41,276] Trial 11 failed with parameters: {'interactions': 15, 'max_bins': 256, 'learning_rate': 0.0013218114173333237, 'outer_bags': 8, 'inner_bags': 8} because of the following error: KeyboardInterrupt().\n","joblib.externals.loky.process_executor._RemoteTraceback: \n","\"\"\"\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n","    r = call_item()\n","        ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n","    return self.fn(*self.args, **self.kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 607, in __call__\n","    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 607, in <listcomp>\n","    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n","            ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n","    return self.function(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.11/dist-packages/interpret/glassbox/_ebm/_ebm.py\", line 1482, in fit\n","    results = provider.parallel(boost, parallel_args)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/interpret/provider/_compute.py\", line 20, in parallel\n","    return Parallel(n_jobs=self.n_jobs)(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 2072, in __call__\n","    return output if self.return_generator else list(output)\n","                                                ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1682, in _get_outputs\n","    yield from self._retrieve()\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1800, in _retrieve\n","    time.sleep(0.01)\n","KeyboardInterrupt\n","\"\"\"\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/tmp/ipython-input-1-1440243975.py\", line 188, in <lambda>\n","    study_objective = lambda trial: objective(trial, X_train_outer, y_train_outer, inner_cv)\n","                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/tmp/ipython-input-1-1440243975.py\", line 178, in objective\n","    scores = cross_val_score(ebm, X, y, scoring='neg_root_mean_squared_error', cv=cv_splitter, n_jobs=-1)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n","    cv_results = cross_validate(\n","                 ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 411, in cross_validate\n","    results = parallel(\n","              ^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","    return super().__call__(iterable_with_config)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 2072, in __call__\n","    return output if self.return_generator else list(output)\n","                                                ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1682, in _get_outputs\n","    yield from self._retrieve()\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1784, in _retrieve\n","    self._raise_error_fast()\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1859, in _raise_error_fast\n","    error_job.get_result(self.timeout)\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 758, in get_result\n","    return self._return_or_raise()\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 773, in _return_or_raise\n","    raise self._result\n","KeyboardInterrupt\n","[W 2025-07-28 16:17:41,279] Trial 12 failed with parameters: {'interactions': 4, 'max_bins': 256, 'learning_rate': 0.001253377320789469, 'outer_bags': 8, 'inner_bags': 6} because of the following error: RuntimeError(\"The executor underlying Parallel has been shutdown. This is likely due to the garbage collection of a previous generator from a call to Parallel with return_as='generator'. Make sure the generator is not garbage collected when submitting a new job or that it is first properly exhausted.\").\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/_parallel_backends.py\", line 701, in retrieve_result_callback\n","    return future.result()\n","           ^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n","    return self.__get_result()\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n","    raise self._exception\n","joblib.externals.loky.process_executor.ShutdownExecutorError: The Executor was shutdown with `kill_workers=True` before this job could complete.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"/tmp/ipython-input-1-1440243975.py\", line 188, in <lambda>\n","    study_objective = lambda trial: objective(trial, X_train_outer, y_train_outer, inner_cv)\n","                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/tmp/ipython-input-1-1440243975.py\", line 178, in objective\n","    scores = cross_val_score(ebm, X, y, scoring='neg_root_mean_squared_error', cv=cv_splitter, n_jobs=-1)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n","    cv_results = cross_validate(\n","                 ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 411, in cross_validate\n","    results = parallel(\n","              ^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n","    return super().__call__(iterable_with_config)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 2072, in __call__\n","    return output if self.return_generator else list(output)\n","                                                ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1682, in _get_outputs\n","    yield from self._retrieve()\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1784, in _retrieve\n","    self._raise_error_fast()\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1859, in _raise_error_fast\n","    error_job.get_result(self.timeout)\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 758, in get_result\n","    return self._return_or_raise()\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 773, in _return_or_raise\n","    raise self._result\n","RuntimeError: The executor underlying Parallel has been shutdown. This is likely due to the garbage collection of a previous generator from a call to Parallel with return_as='generator'. Make sure the generator is not garbage collected when submitting a new job or that it is first properly exhausted.\n","[W 2025-07-28 16:17:41,300] Trial 11 failed with value None.\n","[W 2025-07-28 16:17:41,310] Trial 12 failed with value None.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-1440243975.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mstudy_objective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[0;32m--> 489\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                         \u001b[0mcompleted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFIRST_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                         \u001b[0;31m# Raise if exception occurred in executing the completed futures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_and_install_waiters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","EBM Training, Evaluation, and Interpretation for Coastal Wave Forecasting\n","\n","This script executes Phases 2-4 of the research plan for predicting\n","significant wave height (buoy_main_hs) using an Explainable Boosting Machine (EBM).\n","\n","Phase 2: Hyperparameter Optimization with Nested, Blocked Cross-Validation.\n","Phase 3: Final Model Training, Saving, and Out-of-Sample (OOS) Evaluation.\n","Phase 4: Interpretation and Visualization for Publication.\n","\n","Environment: Google Colab\n","Libraries: pandas, numpy, scikit-learn, interpret, optuna, pickle, matplotlib, seaborn\n","\"\"\"\n","\n","# =============================================================================\n","# Step 1: Setup and Data Preparation\n","# =============================================================================\n","print(\"--- Step 1: Setup and Data Preparation ---\")\n","\n","!pip install optuna interpret\n","\n","# --- 1.1. Imports and Setup ---\n","import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import optuna\n","\n","from google.colab import drive\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection._split import BaseCrossValidator\n","from interpret.glassbox import ExplainableBoostingRegressor\n","from interpret import show\n","\n","# Suppress Optuna's informational messages for cleaner output\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","# --- 1.2. Mount Google Drive ---\n","print(\"Mounting Google Drive...\")\n","try:\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\"Google Drive mounted successfully.\")\n","except Exception as e:\n","    print(f\"Error mounting Google Drive: {e}\")\n","\n","\n","# --- 1.3. Plotting Style Configuration ---\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (10, 6)\n","plt.rcParams['figure.dpi'] = 450\n","\n","# --- 1.4. Paths and Directories ---\n","PROJECT_ROOT = '/content/drive/My Drive/Paper_3_New'\n","\n","INPUT_FILE_PATH = os.path.join(\n","    PROJECT_ROOT,\n","    'Outputs/Feature_Engineering_v1/final_engineered_features_v3.csv'\n",")\n","\n","OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'Outputs/Modeling_v1/EBM')\n","\n","print(f\"Output directory will be: {OUTPUT_DIR}\")\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","\n","# --- 1.5. Data Loading and Preparation ---\n","def load_and_prepare_data(filepath):\n","    \"\"\"\n","    Loads the engineered features, parses datetime, and splits the data.\n","    \"\"\"\n","    print(f\"Attempting to load data from: {filepath}\")\n","    try:\n","        df = pd.read_csv(filepath)\n","    except FileNotFoundError:\n","        print(f\"\\nCRITICAL ERROR: Input file not found at the specified path.\")\n","        print(\"Please ensure the feature engineering script has run successfully.\")\n","        return None, None\n","\n","    df['time'] = pd.to_datetime(df['time'])\n","    df.set_index('time', inplace=True)\n","\n","    # --- FIX: Corrected the values to match the feature engineering script's output ---\n","    df_train_val = df[df['split'] == 'Train_Val'].copy()\n","    df_oos = df[df['split'] == 'OOS'].copy()\n","\n","    # Drop the 'split' column as it's no longer needed\n","    df_train_val.drop(columns=['split'], inplace=True)\n","    df_oos.drop(columns=['split'], inplace=True)\n","\n","    print(f\"Data loaded successfully.\")\n","    print(f\"Training/Validation set shape: {df_train_val.shape}\")\n","    print(f\"Out-of-Sample (OOS) set shape: {df_oos.shape}\")\n","\n","    return df_train_val, df_oos\n","\n","df_train_val, df_oos = load_and_prepare_data(INPUT_FILE_PATH)\n","\n","# --- 1.6. Feature and Target Separation and Main Execution Block ---\n","if df_train_val is not None and df_oos is not None and not df_train_val.empty:\n","    TARGET = 'buoy_main_hs'\n","\n","    # Identify feature columns by excluding ALL columns that start with 'buoy_main_'\n","    feature_cols = [col for col in df_train_val.columns if not col.startswith('buoy_main_')]\n","\n","    print(f\"Target variable: {TARGET}\")\n","    print(f\"Number of features: {len(feature_cols)}\")\n","\n","    X_train_val = df_train_val[feature_cols]\n","    y_train_val = df_train_val[TARGET]\n","\n","    X_oos = df_oos[feature_cols]\n","    y_oos = df_oos[TARGET]\n","\n","    # =============================================================================\n","    # Step 2: Implement the Nested, Blocked Cross-Validation Framework\n","    # =============================================================================\n","    print(\"\\n--- Step 2: Implementing Blocked Time Series CV ---\")\n","\n","    class BlockedTimeSeriesSplit(BaseCrossValidator):\n","        \"\"\"\n","        Custom time series cross-validator that adds a 'gap' between train and test sets.\n","        \"\"\"\n","        def __init__(self, n_splits=5, gap=24):\n","            self.n_splits = n_splits\n","            self.gap = gap\n","\n","        def get_n_splits(self, X=None, y=None, groups=None):\n","            return self.n_splits\n","\n","        def split(self, X, y=None, groups=None):\n","            n_samples = len(X)\n","            k_fold_size = n_samples // self.n_splits\n","            indices = np.arange(n_samples)\n","\n","            for i in range(self.n_splits):\n","                start = i * k_fold_size\n","                stop = start + k_fold_size\n","                mid = int(0.8 * (stop - start)) + start\n","\n","                if i < self.n_splits - 1:\n","                    train_indices = indices[start:mid]\n","                    test_indices = indices[mid + self.gap:stop]\n","                else:\n","                    train_indices = indices[start:mid]\n","                    test_indices = indices[mid + self.gap:]\n","\n","                yield train_indices, test_indices\n","\n","    outer_cv = BlockedTimeSeriesSplit(n_splits=5, gap=24)\n","    inner_cv = BlockedTimeSeriesSplit(n_splits=3, gap=24)\n","    print(\"BlockedTimeSeriesSplit class defined and CV splitters instantiated.\")\n","\n","\n","    # =============================================================================\n","    # Step 3: Hyperparameter Optimization with Nested CV\n","    # =============================================================================\n","    print(\"\\n--- Step 3: Hyperparameter Optimization with Nested CV ---\")\n","    print(\"This step will take a significant amount of time.\")\n","\n","    def objective(trial, X, y, cv_splitter):\n","        \"\"\"\n","        Optuna objective function for hyperparameter tuning of the EBM.\n","        \"\"\"\n","        params = {\n","            'interactions': trial.suggest_int('interactions', 0, 15),\n","            'max_bins': trial.suggest_categorical('max_bins', [128, 256, 512]),\n","            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n","            'outer_bags': trial.suggest_int('outer_bags', 8, 16),\n","            'inner_bags': trial.suggest_int('inner_bags', 0, 8),\n","            'n_jobs': -1,\n","            'random_state': 42\n","        }\n","        ebm = ExplainableBoostingRegressor(**params)\n","        scores = cross_val_score(ebm, X, y, scoring='neg_root_mean_squared_error', cv=cv_splitter, n_jobs=-1)\n","        return np.mean(scores)\n","\n","    outer_fold_scores = []\n","    fold_counter = 1\n","    for train_idx, val_idx in outer_cv.split(X_train_val, y_train_val):\n","        print(f\"\\n--- Starting Outer Fold {fold_counter}/{outer_cv.get_n_splits()} ---\")\n","        X_train_outer, y_train_outer = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n","        X_val_outer, y_val_outer = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n","\n","        study_objective = lambda trial: objective(trial, X_train_outer, y_train_outer, inner_cv)\n","        study = optuna.create_study(direction='maximize')\n","        study.optimize(study_objective, n_trials=50, n_jobs=-1)\n","\n","        best_params = study.best_params\n","        print(f\"Best params for fold {fold_counter}: {best_params}\")\n","        print(f\"Best score for fold {fold_counter}: {-study.best_value:.4f} (RMSE)\")\n","\n","        ebm_fold = ExplainableBoostingRegressor(**best_params, n_jobs=-1, random_state=42)\n","        ebm_fold.fit(X_train_outer, y_train_outer)\n","        preds = ebm_fold.predict(X_val_outer)\n","        rmse_score = np.sqrt(mean_squared_error(y_val_outer, preds))\n","        outer_fold_scores.append(rmse_score)\n","        print(f\"RMSE on outer validation set for fold {fold_counter}: {rmse_score:.4f}\")\n","        fold_counter += 1\n","\n","    mean_rmse = np.mean(outer_fold_scores)\n","    std_rmse = np.std(outer_fold_scores)\n","    print(\"\\n--- Nested Cross-Validation Results ---\")\n","    print(f\"Unbiased EBM Performance Estimate (RMSE)\")\n","    print(f\"Mean: {mean_rmse:.4f}\")\n","    print(f\"Standard Deviation: {std_rmse:.4f}\")\n","\n","\n","    # =============================================================================\n","    # Step 4: Final Model Training, Saving, and OOS Evaluation\n","    # =============================================================================\n","    print(\"\\n--- Step 4: Final Model Training and OOS Evaluation ---\")\n","\n","    print(\"Running final, extensive hyperparameter search on all training data...\")\n","    final_objective = lambda trial: objective(trial, X_train_val, y_train_val, inner_cv)\n","    final_study = optuna.create_study(direction='maximize')\n","    final_study.optimize(final_objective, n_trials=100, n_jobs=-1)\n","    final_best_params = final_study.best_params\n","    print(f\"Absolute best hyperparameters found: {final_best_params}\")\n","    print(f\"Best CV score (RMSE): {-final_study.best_value:.4f}\")\n","\n","    print(\"Training final model on the entire X_train_val dataset...\")\n","    final_ebm = ExplainableBoostingRegressor(**final_best_params, n_jobs=-1, random_state=42)\n","    final_ebm.fit(X_train_val, y_train_val)\n","    print(\"Final model training complete.\")\n","\n","    model_path = os.path.join(OUTPUT_DIR, 'ebm_final_model_hs.pkl')\n","    with open(model_path, 'wb') as f:\n","        pickle.dump(final_ebm, f)\n","    print(f\"Final model saved to: {model_path}\")\n","\n","    print(\"Evaluating final model on the held-out Out-of-Sample (OOS) data...\")\n","    with open(model_path, 'rb') as f:\n","        loaded_ebm = pickle.load(f)\n","    oos_preds = loaded_ebm.predict(X_oos)\n","    oos_rmse = np.sqrt(mean_squared_error(y_oos, oos_preds))\n","    oos_r2 = r2_score(y_oos, oos_preds)\n","\n","    def calculate_csi(y_true, y_pred, threshold):\n","        \"\"\"Calculates the Critical Success Index (CSI).\"\"\"\n","        true_positives = np.sum((y_true > threshold) & (y_pred > threshold))\n","        false_positives = np.sum((y_true <= threshold) & (y_pred > threshold))\n","        false_negatives = np.sum((y_true > threshold) & (y_pred <= threshold))\n","        denominator = true_positives + false_positives + false_negatives\n","        return true_positives / denominator if denominator != 0 else 0.0\n","\n","    hazard_threshold = 2.5\n","    oos_csi = calculate_csi(y_oos, oos_preds, hazard_threshold)\n","\n","    print(\"\\n--- Final OOS Performance Report ---\")\n","    print(f\"RMSE: {oos_rmse:.4f}\")\n","    print(f\"R-squared (R²): {oos_r2:.4f}\")\n","    print(f\"Critical Success Index (CSI) for Hm0 > {hazard_threshold}m: {oos_csi:.4f}\")\n","\n","    report_path = os.path.join(OUTPUT_DIR, 'oos_performance_report.txt')\n","    with open(report_path, 'w') as f:\n","        f.write(\"--- Final OOS Performance Report ---\\n\")\n","        f.write(f\"RMSE: {oos_rmse:.4f}\\n\")\n","        f.write(f\"R-squared (R²): {oos_r2:.4f}\\n\")\n","        f.write(f\"Critical Success Index (CSI) for Hm0 > {hazard_threshold}m: {oos_csi:.4f}\\n\")\n","    print(f\"Performance report saved to: {report_path}\")\n","\n","\n","    # =============================================================================\n","    # Step 5: Interpretation and Visualization for Publication\n","    # =============================================================================\n","    print(\"\\n--- Step 5: Generating Interpretation Plots ---\")\n","\n","    print(\"Generating global explanation plots...\")\n","    global_exp = loaded_ebm.explain_global(name='EBM_Global')\n","\n","    importance_data = global_exp.data()\n","    feature_importances = pd.DataFrame({\n","        'feature': importance_data['names'],\n","        'importance': importance_data['scores']\n","    }).sort_values(by='importance', ascending=False)\n","\n","    plt.figure(figsize=(12, 8))\n","    sns.barplot(x='importance', y='feature', data=feature_importances.head(20), palette='viridis')\n","    plt.title('Top 20 Feature Importances (Global)', fontsize=16)\n","    plt.xlabel('Mean Absolute Value (Impact on Model Output)', fontsize=12)\n","    plt.ylabel('Feature', fontsize=12)\n","    plt.tight_layout()\n","    fig_path = os.path.join(OUTPUT_DIR, 'global_feature_importance_top20.png')\n","    plt.savefig(fig_path, dpi=450)\n","    plt.close()\n","    print(f\"Saved feature importance plot to: {fig_path}\")\n","\n","    top_10_features = feature_importances['feature'].head(10).tolist()\n","    print(\"Generating response curves for top 10 features...\")\n","    for feature_name in top_10_features:\n","        feature_index = global_exp.feature_names.index(feature_name)\n","        feature_data = global_exp.data(feature_index)\n","        plt.figure(figsize=(8, 5))\n","        plt.plot(feature_data['names'], feature_data['scores'], color='b')\n","        if 'upper_bounds' in feature_data and 'lower_bounds' in feature_data:\n","            plt.fill_between(feature_data['names'], feature_data['lower_bounds'], feature_data['upper_bounds'], color='b', alpha=0.2)\n","        plt.title(f'Response Curve for: {feature_name}', fontsize=14)\n","        plt.xlabel(f'Value of {feature_name}', fontsize=12)\n","        plt.ylabel('Contribution to Prediction (log-odds)', fontsize=12)\n","        plt.tight_layout()\n","        fig_path = os.path.join(OUTPUT_DIR, f'response_curve_{feature_name}.png')\n","        plt.savefig(fig_path, dpi=450)\n","        plt.close()\n","\n","    print(\"Generating interaction heatmaps for top 5 interactions...\")\n","    interaction_data = global_exp.data(key='interactions')\n","    interaction_scores = sorted(interaction_data, key=lambda x: -x[1])\n","    for i in range(min(5, len(interaction_scores))):\n","        interaction_index = interaction_scores[i][0]\n","        interaction_exp = global_exp.data(interaction_index)\n","        feature_1_name = global_exp.feature_names[interaction_exp['left_names']]\n","        feature_2_name = global_exp.feature_names[interaction_exp['right_names']]\n","        fig = plt.figure(figsize=(8, 6))\n","        ax = fig.add_subplot(111)\n","        cax = ax.imshow(interaction_exp['scores'], cmap='RdBu', origin='lower')\n","        fig.colorbar(cax, label='Interaction Contribution')\n","        ax.set_xticks(np.arange(len(interaction_exp['xtick_vals'])))\n","        ax.set_yticks(np.arange(len(interaction_exp['ytick_vals'])))\n","        ax.set_xticklabels([f\"{x:.2f}\" for x in interaction_exp['xtick_vals']], rotation=45, ha=\"right\")\n","        ax.set_yticklabels([f\"{y:.2f}\" for y in interaction_exp['ytick_vals']])\n","        ax.set_xlabel(feature_2_name)\n","        ax.set_ylabel(feature_1_name)\n","        ax.set_title(f'Interaction: {feature_1_name} vs {feature_2_name}')\n","        plt.tight_layout()\n","        fig_path = os.path.join(OUTPUT_DIR, f'interaction_{i+1}_{feature_1_name}_vs_{feature_2_name}.png')\n","        plt.savefig(fig_path, dpi=450)\n","        plt.close()\n","\n","    print(\"Generating local explanations for the 3 highest wave events in OOS...\")\n","    storm_peak_indices = y_oos.nlargest(3).index\n","    for i, timestamp in enumerate(storm_peak_indices):\n","        print(f\"Generating explanation for storm peak #{i+1} at {timestamp}...\")\n","        instance_to_explain = X_oos.loc[[timestamp]]\n","        local_exp = loaded_ebm.explain_local(instance_to_explain, name=f'EBM_Local_Storm_{i+1}')\n","        fig = show(local_exp, show_selector=False)\n","        fig_path = os.path.join(OUTPUT_DIR, f'local_explanation_storm_{i+1}_{timestamp.strftime(\"%Y%m%d\")}.png')\n","        fig.savefig(fig_path, dpi=450, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Saved local explanation plot to: {fig_path}\")\n","\n","    print(\"\\n--- All Phases Complete ---\")\n","    print(f\"All outputs (model, reports, figures) are saved in: {OUTPUT_DIR}\")\n","\n","else:\n","    print(\"\\nHalting script because data loading failed or the training dataframe is empty.\")\n","    print(\"Please check the input file path and ensure the 'split' column contains 'Train_Val' and 'OOS' values.\")\n","\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1P2LMCZ3N6PgKLd9oeL10f5b9iquYQwJL","authorship_tag":"ABX9TyNRYly8ewYRY3WHV2UT2rOR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}